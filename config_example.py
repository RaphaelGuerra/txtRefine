"""
Example configuration file for the Text Refinement Program

Copy this file to 'config.py' and modify the settings according to your needs.
"""

# Default Ollama model to use
DEFAULT_MODEL = "gemma:2b"

# Chunk processing settings
MAX_WORDS_PER_CHUNK = 800      # Maximum words per chunk
MIN_WORDS_PER_CHUNK = 400      # Minimum words per chunk (for fallback)
CHUNK_OVERLAP_WORDS = 50       # Overlap between chunks (not currently used)

# Text processing settings
MAX_RETRIES = 3                # Maximum retry attempts for failed chunks
RETRY_DELAY_SECONDS = 2        # Delay between retries
CONTENT_LOSS_THRESHOLD = 0.7   # If refined text is shorter than 70% of original, retry

# File encoding
DEFAULT_ENCODING = "utf-8"

# Output settings
OUTPUT_PREFIX = "refined_"     # Prefix for output files
OUTPUT_SEPARATOR = "\n\n"      # Separator between chunks in output

# Custom prompt templates
# You can modify these prompts to better suit your specific content type

PHILOSOPHY_REFINEMENT_PROMPT = """Voc√™ √© um especialista em filosofia medieval e escol√°stica, com profundo conhecimento da l√≠ngua portuguesa e da obra de Olavo de Carvalho.

Sua tarefa √© refinar a seguinte transcri√ß√£o de uma aula de filosofia, mantendo a fidelidade absoluta ao conte√∫do original e ao estilo do professor, mas corrigindo:

1. Erros gramaticais √≥bvios do portugu√™s
2. Palavras mal transcritas ou incompletas
3. Frases quebradas ou mal estruturadas
4. Termos filos√≥ficos incorretos

IMPORTANTE:
- N√ÉO resuma, condense ou omita conte√∫do
- Mantenha TODAS as ideias filos√≥ficas originais
- Preserve o estilo coloquial e did√°tico do professor
- Corrija apenas erros √≥bvios de transcri√ß√£o
- Mantenha a estrutura e fluxo da argumenta√ß√£o original

Transcri√ß√£o a refinar (parte {chunk_num} de {total_chunks}):

{chunk}

Refine esta transcri√ß√£o mantendo a fidelidade absoluta ao original:"""

GENERAL_REFINEMENT_PROMPT = """Voc√™ √© um especialista em l√≠ngua portuguesa e transcri√ß√µes.

Sua tarefa √© refinar a seguinte transcri√ß√£o, mantendo a fidelidade absoluta ao conte√∫do original, mas corrigindo:

1. Erros gramaticais √≥bvios
2. Palavras mal transcritas ou incompletas
3. Frases quebradas ou mal estruturadas
4. Quebras de linha inadequadas

IMPORTANTE:
- N√ÉO resuma, condense ou omita conte√∫do
- Mantenha o estilo e tom original
- Corrija apenas erros √≥bvios de transcri√ß√£o
- Preserve a estrutura e fluxo original

Transcri√ß√£o a refinar (parte {chunk_num} de {total_chunks}):

{chunk}

Refine esta transcri√ß√£o mantendo a fidelidade absoluta ao original:"""

# Add your own custom prompt templates here
CUSTOM_REFINEMENT_PROMPT = """Voc√™ √© um especialista em [SEU DOM√çNIO].

Sua tarefa √© refinar a seguinte transcri√ß√£o, mantendo a fidelidade absoluta ao conte√∫do original, mas corrigindo:

1. Erros gramaticais √≥bvios
2. Palavras mal transcritas ou incompletas
3. Frases quebradas ou mal estruturadas
4. Termos t√©cnicos incorretos espec√≠ficos do dom√≠nio

IMPORTANTE:
- N√ÉO resuma, condense ou omita conte√∫do
- Mantenha o estilo e tom original
- Corrija apenas erros √≥bvios de transcri√ß√£o
- Preserve a estrutura e fluxo original

Transcri√ß√£o a refinar (parte {chunk_num} de {total_chunks}):

{chunk}

Refine esta transcri√ß√£o mantendo a fidelidade absoluta ao original:"""

# Model recommendations for different content types
MODEL_RECOMMENDATIONS = {
    "philosophy": {
        "best": ["mistral:7b", "llama2:7b", "gemma:7b"],
        "fast": ["gemma:2b", "llama2:3b"],
        "balanced": ["llama2:7b", "gemma:7b"]
    },
    "general": {
        "best": ["mistral:7b", "llama2:7b"],
        "fast": ["gemma:2b", "llama2:3b"],
        "balanced": ["llama2:7b", "gemma:7b"]
    },
    # Add your own content types here
    "technical": {
        "best": ["mistral:7b", "llama2:7b"],
        "fast": ["gemma:2b", "llama2:3b"],
        "balanced": ["llama2:7b", "gemma:7b"]
    }
}

# Content type detection keywords
# Add keywords specific to your content types
CONTENT_TYPE_KEYWORDS = {
    "philosophy": [
        "filosofia", "escol√°stica", "medieval", "arist√≥teles", "plat√£o", "santo tom√°s",
        "s√£o boaventura", "pedro abelardo", "universais", "realismo", "nominalismo",
        "metaf√≠sica", "ontologia", "epistemologia", "l√≥gica", "√©tica", "teologia"
    ],
    "technical": [
        "programa√ß√£o", "software", "hardware", "algoritmo", "c√≥digo", "sistema",
        "tecnologia", "computador", "internet", "dados", "banco de dados"
    ]
    # Add more content types as needed
}

# Error messages in Portuguese
ERROR_MESSAGES = {
    "ollama_not_found": "‚ùå Erro: Ollama n√£o est√° instalado ou acess√≠vel.",
    "ollama_install_url": "üì• Instale o Ollama em: https://ollama.com/download",
    "model_not_found": "‚ùå Erro: Modelo '{model}' n√£o encontrado.",
    "model_pull_command": "üì• Baixe o modelo executando: ollama pull {model}",
    "input_folder_not_found": "‚ùå Erro: Pasta 'input' n√£o encontrada.",
    "no_files_to_process": "‚ùå Nenhum arquivo .txt encontrado para processar.",
    "file_not_found": "‚ö†Ô∏è  Arquivo n√£o encontrado ou n√£o √© .txt: {filename}",
    "empty_file": "‚ùå Arquivo de entrada vazio",
    "connection_error": "‚ùå Erro: N√£o foi poss√≠vel conectar ao Ollama. Verifique se est√° rodando.",
    "context_length_error": "‚ö†Ô∏è  Chunk {chunk_num} muito longo, tentando dividir...",
    "unexpected_error": "‚ùå Erro inesperado no chunk {chunk_num}: {error}",
    "content_loss_warning": "‚ö†Ô∏è  Aviso: Chunk {chunk_num} pode ter perdido conte√∫do (tentativa {attempt})",
    "using_original": "‚ö†Ô∏è  Usando texto original para chunk {chunk_num}",
    "processing_failed": "‚ùå Falha ao processar: {filename}"
}

# Success messages in Portuguese
SUCCESS_MESSAGES = {
    "using_model": "ü§ñ Usando modelo: {model}",
    "processing_file": "üìñ Processando: {filename}",
    "chunks_created": "üìù Dividido em {count} chunks para processamento",
    "refinement_complete": "‚úÖ Refinamento conclu√≠do: {filename}",
    "statistics": "üìä Estat√≠sticas:",
    "original_chars": "   - Texto original: {count} caracteres",
    "refined_chars": "   - Texto refinado: {count} caracteres",
    "chunks_processed": "   - Chunks processados: {count}",
    "files_processing": "üìÅ Processando {count} arquivo(s)",
    "processing_complete": "üéâ Processamento conclu√≠do!"
}

# Progress bar settings
PROGRESS_BAR_DESC = "Refinando chunks"
PROGRESS_BAR_UNIT = "chunk"

# File patterns
TEXT_FILE_PATTERN = "*.txt"

# Custom settings for your use case
# Uncomment and modify as needed:

# CUSTOM_CHUNK_SIZE = 600  # Smaller chunks for better quality
# CUSTOM_RETRY_COUNT = 5   # More retries for difficult content
# CUSTOM_ENCODING = "latin-1"  # Different encoding if needed
