"""
Configuration file for the Text Refinement Program
"""

# Default Ollama model to use
DEFAULT_MODEL = "llama3.2:latest"

# Chunk processing settings
MAX_WORDS_PER_CHUNK = 800
MIN_WORDS_PER_CHUNK = 400
CHUNK_OVERLAP_WORDS = 50

# Text processing settings
MAX_RETRIES = 3
RETRY_DELAY_SECONDS = 2
CONTENT_LOSS_THRESHOLD = 0.7  # If refined text is shorter than 70% of original, retry

# File encoding
DEFAULT_ENCODING = "utf-8"

# Output settings
OUTPUT_PREFIX = "refined_"
OUTPUT_SEPARATOR = "\n\n"

# Prompt templates
PHILOSOPHY_REFINEMENT_PROMPT = """Voc√™ √© um especialista em filosofia medieval e escol√°stica, com profundo conhecimento da l√≠ngua portuguesa e da obra de Olavo de Carvalho.

Sua tarefa √© refinar a seguinte transcri√ß√£o de uma aula de filosofia, mantendo a fidelidade ABSOLUTA ao conte√∫do original e ao estilo do professor, mas corrigindo APENAS:

1. Erros gramaticais √≥bvios do portugu√™s
2. Palavras mal transcritas ou incompletas (ex: "Col√°ssica" ‚Üí "Escol√°stica")
3. Frases quebradas ou mal estruturadas
4. Termos filos√≥ficos incorretos

REGRAS ESTRITAS:
- N√ÉO resuma, condense ou omita conte√∫do
- N√ÉO adicione novas informa√ß√µes ou explica√ß√µes
- N√ÉO mude o significado ou a estrutura das frases
- N√ÉO altere exemplos, cita√ß√µes ou refer√™ncias
- Mantenha EXATAMENTE o mesmo comprimento e estrutura
- Preserve TODAS as ideias filos√≥ficas originais
- Mantenha o estilo coloquial e did√°tico do professor
- Corrija APENAS erros √≥bvios de transcri√ß√£o
- Mantenha a estrutura e fluxo da argumenta√ß√£o original

Transcri√ß√£o a refinar (parte {chunk_num} de {total_chunks}):

{chunk}

Refine esta transcri√ß√£o mantendo a fidelidade ABSOLUTA ao original, corrigindo APENAS erros de transcri√ß√£o:"""

GENERAL_REFINEMENT_PROMPT = """Voc√™ √© um especialista em l√≠ngua portuguesa e transcri√ß√µes.

Sua tarefa √© refinar a seguinte transcri√ß√£o, mantendo a fidelidade absoluta ao conte√∫do original, mas corrigindo:

1. Erros gramaticais √≥bvios
2. Palavras mal transcritas ou incompletas
3. Frases quebradas ou mal estruturadas
4. Quebras de linha inadequadas

IMPORTANTE:
- N√ÉO resuma, condense ou omita conte√∫do
- Mantenha o estilo e tom original
- Corrija apenas erros √≥bvios de transcri√ß√£o
- Preserve a estrutura e fluxo original

Transcri√ß√£o a refinar (parte {chunk_num} de {total_chunks}):

{chunk}

Refine esta transcri√ß√£o mantendo a fidelidade absoluta ao original:"""

# Model recommendations for different content types
MODEL_RECOMMENDATIONS = {
    "philosophy": {
        "best": ["neural-chat:latest", "openchat:latest", "llama3.2:latest"],
        "fast": ["gemma:2b", "dolphin-phi:latest"],
        "balanced": ["openchat:latest", "llama3.2:latest"]
    },
    "general": {
        "best": ["neural-chat:latest", "openchat:latest", "llama3.2:latest"],
        "fast": ["gemma:2b", "dolphin-phi:latest"],
        "balanced": ["openchat:latest", "llama3.2:latest"]
    },
    "technical": {
        "best": ["neural-chat:latest", "openchat:latest"],
        "fast": ["gemma:2b", "dolphin-phi:latest"],
        "balanced": ["openchat:latest", "llama3.2:latest"]
    }
}

# Model descriptions and characteristics
MODEL_DESCRIPTIONS = {
    "neural-chat:latest": {
        "name": "Neural Chat",
        "description": "High-quality open-source model optimized for chat and instruction following",
        "size": "4.1 GB",
        "quality": "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
        "speed": "‚ö°‚ö°",
        "best_for": "Philosophy, complex reasoning, high-quality output"
    },
    "openchat:latest": {
        "name": "OpenChat",
        "description": "Excellent open-source model with strong reasoning capabilities",
        "size": "4.1 GB",
        "quality": "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
        "speed": "‚ö°‚ö°",
        "best_for": "Academic content, philosophy, detailed analysis"
    },
    "llama3.2:latest": {
        "name": "Llama 3.2",
        "description": "Meta's latest open-source model with strong performance",
        "size": "2.0 GB",
        "quality": "‚≠ê‚≠ê‚≠ê‚≠ê",
        "speed": "‚ö°‚ö°‚ö°",
        "best_for": "General purpose, good balance of quality and speed"
    },
    "dolphin-phi:latest": {
        "name": "Dolphin Phi",
        "description": "Microsoft's Phi model optimized for instruction following",
        "size": "1.6 GB",
        "quality": "‚≠ê‚≠ê‚≠ê‚≠ê",
        "speed": "‚ö°‚ö°‚ö°",
        "best_for": "Fast processing, good quality for size"
    },
    "gemma:2b": {
        "name": "Gemma 2B",
        "description": "Google's lightweight but capable model",
        "size": "1.7 GB",
        "quality": "‚≠ê‚≠ê‚≠ê",
        "speed": "‚ö°‚ö°‚ö°‚ö°",
        "best_for": "Quick processing, basic refinement tasks"
    }
}

# Content type detection keywords
CONTENT_TYPE_KEYWORDS = {
    "philosophy": [
        "filosofia", "escol√°stica", "escol√°stico", "medieval", "arist√≥teles", "plat√£o", "santo tom√°s",
        "s√£o boaventura", "pedro abelardo", "universais", "realismo", "nominalismo",
        "metaf√≠sica", "ontologia", "epistemologia", "l√≥gica", "√©tica", "teologia",
        "padres", "igreja", "crist√£", "crist√£o", "religioso", "religiosa", "espiritual",
        "alma", "deus", "divino", "sagrado", "sagrada", "escritura", "evangelho",
        "academia", "intelectual", "intelectuais", "coletividade", "comunidade"
    ]
}

# Error messages in Portuguese
ERROR_MESSAGES = {
    "ollama_not_found": "‚ùå Erro: Ollama n√£o est√° instalado ou acess√≠vel.",
    "ollama_install_url": "üì• Instale o Ollama em: https://ollama.com/download",
    "model_not_found": "‚ùå Erro: Modelo '{model}' n√£o encontrado.",
    "model_pull_command": "üì• Baixe o modelo executando: ollama pull {model}",
    "input_folder_not_found": "‚ùå Erro: Pasta 'input' n√£o encontrada.",
    "no_files_to_process": "‚ùå Nenhum arquivo .txt encontrado para processar.",
    "file_not_found": "‚ö†Ô∏è  Arquivo n√£o encontrado ou n√£o √© .txt: {filename}",
    "empty_file": "‚ùå Arquivo de entrada vazio",
    "connection_error": "‚ùå Erro: N√£o foi poss√≠vel conectar ao Ollama. Verifique se est√° rodando.",
    "context_length_error": "‚ö†Ô∏è  Chunk {chunk_num} muito longo, tentando dividir...",
    "unexpected_error": "‚ùå Erro inesperado no chunk {chunk_num}: {error}",
    "content_loss_warning": "‚ö†Ô∏è  Aviso: Chunk {chunk_num} pode ter perdido conte√∫do (tentativa {attempt})",
    "using_original": "‚ö†Ô∏è  Usando texto original para chunk {chunk_num}",
    "processing_failed": "‚ùå Falha ao processar: {filename}"
}

# Success messages in Portuguese
SUCCESS_MESSAGES = {
    "using_model": "ü§ñ Usando modelo: {model}",
    "processing_file": "üìñ Processando: {filename}",
    "chunks_created": "üìù Dividido em {count} chunks para processamento",
    "refinement_complete": "‚úÖ Refinamento conclu√≠do: {filename}",
    "statistics": "üìä Estat√≠sticas:",
    "original_chars": "   - Texto original: {count} caracteres",
    "refined_chars": "   - Texto refinado: {count} caracteres",
    "chunks_processed": "   - Chunks processados: {count}",
    "files_processing": "üìÅ Processando {count} arquivo(s)",
    "processing_complete": "üéâ Processamento conclu√≠do!"
}

# Progress bar settings
PROGRESS_BAR_DESC = "Refinando chunks"
PROGRESS_BAR_UNIT = "chunk"

# File patterns
TEXT_FILE_PATTERN = "*.txt"
